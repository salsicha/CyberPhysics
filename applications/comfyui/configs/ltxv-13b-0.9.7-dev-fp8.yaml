pipeline_type: multi-scale
checkpoint_path: "ltxv-13b-0.9.7-dev-fp8.safetensors"
downscale_factor: 0.6666666
spatial_upscaler_model_path: "ltxv-spatial-upscaler-0.9.7.safetensors"
stg_mode: "attention_values" # options: "attention_values", "attention_skip", "residual", "transformer_block"
decode_timestep: 0.05
decode_noise_scale: 0.025
text_encoder_model_name_or_path: "PixArt-alpha/PixArt-XL-2-1024-MS"
precision: "bfloat16"
sampler: "from_checkpoint" # options: "uniform", "linear-quadratic", "from_checkpoint"
prompt_enhancement_words_threshold: 120
prompt_enhancer_image_caption_model_name_or_path: "MiaoshouAI/Florence-2-large-PromptGen-v2.0"
prompt_enhancer_llm_model_name_or_path: "unsloth/Llama-3.2-3B-Instruct"
stochastic_sampling: false


first_pass:
  guidance_scale: [3]
  stg_scale: [1]
  rescaling_scale: [0.7]
  guidance_timesteps: [1.0]
  skip_block_list: [19] # [[1], [1,2], [1,2,3], [27], [28], [28]]
  num_inference_steps: 30

second_pass:
  guidance_scale: [3]
  stg_scale: [1]
  rescaling_scale: [0.7]
  guidance_timesteps: [1.0]
  skip_block_list: [19] # [[1], [1,2], [1,2,3], [27], [28], [28]]
  num_inference_steps: 10
  strength: 0.85